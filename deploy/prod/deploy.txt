--------------------------------prometheus相关-----------------------------------------
0. 准备环境prometheus环境（ECS配置与机器数量及指标有关）
   1)ECS 4核8G
   2)分配200G磁盘
   3)安装docker最新版
1. 启动prometheus环境
   docker-compose up -d -f docker-compose-prom.yml
2. 检查prometheus (主要功能是去各种export及puhsgateway上采集数据）
   curl http://localhost:9090
   curl -X POST http://localhost:9090/-/reload  不重启prometheus重新加载配置
3. 检查pushgateway (主要接收flink任务推送，然后暴露http给prometheus采集）
   curl http://localhost:9091/metrics
   echo "test_metric 123456" | curl --data-binary @- http://localhost:9091/metrics/job/test_job
5. 检查alertmanger（主要功能是告警去重、分组、路由等信息在alertmanager.yml)
   curl http://localhost:9093
4. 检查grafana
   curl http://localhost:3000
   默认为admin/flink

---------------------------------flink任务相关---------------------------------------------
一、本地部署方式（无flink产品场景）
    0. 准备环境flink环境（ECS配置与采集任务数有关，如果量少可以与prometheus部在同一机器上）
       1)ECS 4核8G
       2)分配 200G磁盘（主要记录运行时日志）
       3)安装docker最新版
       4)做sls的singletunnel到ecs，另外需要在docker-compose中加上sls的解析
    1. 启动flink采集应用(需要在compose中修改extra_hosts，配置sls域名解析）
       docker-compose up -d -f docker-compose-prom.yml
    2. 复制connector、udf函数到容器并重启容器（jobmanager及taskmanager都需要复制）
        a=("jobmanager" "taskmanager1" "taskmanager2")
        for cntr in ${a[@]};do
            docker cp lib/flink-udx-1.0-all.jar $cntr:/opt/flink/lib/;
            docker cp lib/mysql-connector-java-8.0.11.jar $cntr:/opt/flink/lib/;
            docker cp lib/flink-connector-jdbc-3.1.2-1.18.jar $cntr:/opt/flink/lib/;
            docker cp lib/flink-sql-connector-mysql-cdc-2.4.2.jar $cntr:/opt/flink/lib/;
            docker cp lib/flink-connector-pushgateway-1.0-all.jar  $cntr:/opt/flink/lib/;
            docker cp lib/ververica-connector-common-1.15-vvr-6.0.7-SNAPSHOT-jar-with-dependencies.jar $cntr:/opt/flink/lib/;
            docker cp lib/ververica-connector-datahub-1.15-vvr-6.0.7-SNAPSHOT-jar-with-dependencies.jar $cntr:/opt/flink/lib/;
            docker cp lib/ververica-connector-sls-1.15-vvr-6.0.7-SNAPSHOT-jar-with-dependencies.jar $cntr:/opt/flink/lib/;
            docker exec $cntr mkdir -p /opt/flink/scripts
            docker exec $cntr mkdir -p /opt/flink/data;
            docker exec $cntr restart
        done
    3. 配置环境信息并生成默认flink作业脚本到out目录中，自己定制脚本可放customize脚本中
       vi flink/prod.env   （依现场环境配置相关信息）
       cd flink && sh ./gen.sh
    4. 部署flink作业（只需把作文件复制到jobmanager,然后jobmanager容器中部署脚本）
       docker cp flink/sql-client-init.sql jobmanager:/opt/flink/scripts/
       docker cp flink/runtime/*.sql       jobmanager:/opt/flink/scripts/
       docker exec -it jobmanager bash
       ./bin/sql-client.sh -i scripts/sql-client-init.sql
       ./bin/sql-client.sh -f scripts/sql-client-file.sql
    5. 检查flink作业是否正常运行。
二、flink vvp部署方式（现场有flink vvp产品时）
    1、作业开发\connectors, 点连接器上面的+, 然后选择flink-connector-pushgateway-1.0-all.jar，后面参数全部默认，然后完成。
    2、作业开发\UDF，点UDF注册，选择flink-udx-1.0-all.jar，系统会自动扫描包中的函数
    3、作业开发\Drafts，然后按flink/runtime/目录中需要的脚本依次手动创建作业，语法验证无误后提交运行
    4、检查作业运行正常，数据抽取正常。